{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gwgwa\\Anaconda3\\lib\\site-packages\\deap\\tools\\_hypervolume\\pyhv.py:33: ImportWarning: Falling back to the python version of hypervolume module. Expect this to be very slow.\n",
      "  \"module. Expect this to be very slow.\", ImportWarning)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import operator\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from deap import algorithms\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "from deap import gp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "# machine learning auxiliaries\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age', 'Cabin', 'Embarked']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns[train_data.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Pclass  Sex  Age  SibSp  Parch     Fare  Embarked  \\\n",
      "PassengerId                                                      \n",
      "734             100    0  3.0      0      0  13.0000         2   \n",
      "157              10    1  4.0      0      0   7.7333         1   \n",
      "124             100    1  3.0      0      0  13.0000         2   \n",
      "370            1000    1  3.0      0      0  69.3000         0   \n",
      "321              10    0  3.0      0      0   7.2500         2   \n",
      "\n",
      "             WealthAgeFareRatio  Family  \n",
      "PassengerId                              \n",
      "734                         4.0       1  \n",
      "157                         2.0       1  \n",
      "124                         4.0       1  \n",
      "370                       256.0       1  \n",
      "321                         2.0       1  \n",
      "PassengerId\n",
      "734    0\n",
      "157    1\n",
      "124    1\n",
      "370    1\n",
      "321    0\n",
      "Name: Survived, dtype: int64\n",
      "             Pclass  Sex  Age  SibSp  Parch     Fare  Embarked  \\\n",
      "PassengerId                                                      \n",
      "892              10    0  3.0      0      0   7.8292         1   \n",
      "893              10    1  2.0      1      0   7.0000         2   \n",
      "894             100    0  2.0      0      0   9.6875         1   \n",
      "895              10    0  3.0      0      0   8.6625         2   \n",
      "896              10    1  3.0      1      1  12.2875         2   \n",
      "\n",
      "             WealthAgeFareRatio  Family  \n",
      "PassengerId                              \n",
      "892                         2.0       1  \n",
      "893                         4.0       4  \n",
      "894                         4.0       1  \n",
      "895                         4.0       1  \n",
      "896                        16.0       9  \n"
     ]
    }
   ],
   "source": [
    "train_data.drop(columns=['Name', 'Ticket', 'Cabin'], inplace=True)\n",
    "train_data.set_index(keys=['PassengerId'], drop=True, inplace=True)\n",
    "\n",
    "#train_data.head()\n",
    "\n",
    "test_data.drop(columns=['Name', 'Ticket', 'Cabin'], inplace=True)\n",
    "test_data.set_index(keys=['PassengerId'], drop=True, inplace=True)\n",
    "\n",
    "train_nan_map = {'Age': train_data['Age'].mean(), 'Fare': train_data['Fare'].mean(), 'Embarked': train_data['Embarked'].mode()[0]}\n",
    "test_nan_map = {'Age': test_data['Age'].mean(), 'Fare': test_data['Fare'].mean(), 'Embarked': test_data['Embarked'].mode()[0]}\n",
    "\n",
    "train_data.fillna(value=train_nan_map, inplace=True)\n",
    "test_data.fillna(value=test_nan_map, inplace=True)\n",
    "\n",
    "columns_map = {'Embarked': {'C': 0, 'Q': 1, 'S': 2}, 'Sex': {'male': 0, 'female': 1}}\n",
    "train_data.replace(columns_map, inplace=True)\n",
    "test_data.replace(columns_map, inplace=True)\n",
    "\n",
    "def family(df):\n",
    "    df[\"Family\"] = df[\"SibSp\"] + df[\"Parch\"] + 1\n",
    "    df[\"Family\"] = df[\"Family\"] * df[\"Family\"]\n",
    "    return df\n",
    "\n",
    "def wealth_age_fare_ratio(df):\n",
    "    df[\"WealthAgeFareRatio\"] = df[\"Pclass\"] * df[\"Fare\"] / df[\"Age\"]\n",
    "    #df[\"WealthAgeFareRatio\"] = df[\"WealthAgeFareRatio\"] * df[\"WealthAgeFareRatio\"]\n",
    "    df.loc[ df[\"WealthAgeFareRatio\"] <= 0, \"WealthAgeFareRatio\"] = 0\n",
    "    df.loc[(df[\"WealthAgeFareRatio\"] > 0) & (df[\"WealthAgeFareRatio\"] <= 7.90), \"WealthAgeFareRatio\"] = 2\n",
    "    df.loc[(df[\"WealthAgeFareRatio\"] > 7.90) & (df[\"WealthAgeFareRatio\"] <= 10.84), \"WealthAgeFareRatio\"] = 4\n",
    "    df.loc[(df[\"WealthAgeFareRatio\"] > 10.84) & (df[\"WealthAgeFareRatio\"] <= 19.8), \"WealthAgeFareRatio\"] = 16\n",
    "    df.loc[ df[\"WealthAgeFareRatio\"] > 19.8, \"WealthAgeFareRatio\"] = 256\n",
    "    return df\n",
    "\n",
    "def age_range(df):\n",
    "    df.loc[ df[\"Age\"] <= 0, \"Age\"] = 6\n",
    "    df.loc[(df[\"Age\"] > 0) & (df[\"Age\"] <= 13), \"Age\"] = 5\n",
    "    df.loc[(df[\"Age\"] > 13) & (df[\"Age\"] <= 18), \"Age\"] = 4\n",
    "    df.loc[(df[\"Age\"] > 18) & (df[\"Age\"] <= 40), \"Age\"] = 3\n",
    "    df.loc[(df[\"Age\"] > 40) & (df[\"Age\"] <= 65), \"Age\"] = 2\n",
    "    df.loc[ df[\"Age\"] > 65, \"Age\"] = 1\n",
    "    return df\n",
    "\n",
    "def class_range(df):\n",
    "    df.loc[ df[\"Pclass\"] <= 1, \"Pclass\"] = 1000\n",
    "    df.loc[(df[\"Pclass\"] > 1) & (df[\"Pclass\"] <= 2), \"Pclass\"] = 100\n",
    "    df.loc[(df[\"Pclass\"] > 2) & (df[\"Pclass\"] <= 3), \"Pclass\"] = 10\n",
    "    return df\n",
    "\n",
    "train_data = age_range(train_data)\n",
    "test_data = age_range(test_data)\n",
    "\n",
    "train_data = wealth_age_fare_ratio(train_data)\n",
    "test_data = wealth_age_fare_ratio(test_data)\n",
    "\n",
    "train_data = class_range(train_data)\n",
    "test_data = class_range(test_data)\n",
    "\n",
    "train_data = family(train_data)\n",
    "test_data = family(test_data)\n",
    "\n",
    "#train_data.drop(columns=['Fare'], inplace=True)\n",
    "#test_data.drop(columns=['Fare'], inplace=True)\n",
    "#train_data.to_csv('testtrain.csv', header=True, sep=',')\n",
    "#test_data.to_csv('testtest.csv', header=True, sep=',')\n",
    "\n",
    "X_train = train_data.loc[:, train_data.columns != 'Survived']\n",
    "y_train = train_data.loc[:, 'Survived']\n",
    "\n",
    "y_train.to_csv('y_train.csv', header=True, sep=',')\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.33, random_state=10)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.99, random_state=10)\n",
    "\n",
    "print(X_train.head())\n",
    "print(y_train.head())\n",
    "print(test_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>WealthAgeFareRatio</th>\n",
       "      <th>Family</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Survived, Pclass, Sex, Age, SibSp, Parch, Fare, Embarked, WealthAgeFareRatio, Family]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns[train_data.isna().any()].tolist()\n",
    "train_data[train_data['Embarked'].isna() == True]\n",
    "#train_data['Embarked']\n",
    "#test_data.columns[test_data.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "creator.create(\"FitnessMin\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", gp.PrimitiveTree, fitness=creator.FitnessMin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pset = gp.PrimitiveSet(\"MAIN\", arity=1)\n",
    "pset.addPrimitive(np.add, arity=2)\n",
    "pset.addPrimitive(np.subtract, arity=2)\n",
    "pset.addPrimitive(np.multiply, arity=2)\n",
    "pset.addPrimitive(np.negative, arity=1)\n",
    "pset.addPrimitive(np.positive, arity=1)\n",
    "pset.addPrimitive(np.sin, arity=1)\n",
    "pset.addPrimitive(np.cos, arity=1)\n",
    "pset.addPrimitive(np.tan, arity=1)\n",
    "pset.renameArguments(ARG0='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"expr\", gp.genHalfAndHalf, pset=pset, min_=1, max_=2)\n",
    "toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.expr)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"compile\", gp.compile, pset=pset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalSymbReg(individual, points, pset):\n",
    "    func = gp.compile(expr=individual, pset=pset)\n",
    "    sqerrors = (func(points)-(points**4 + points**3 + points**2 + points))**2\n",
    "    return (np.sqrt(np.sum(sqerrors) / len(points)),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox.register(\"evaluate\", evalSymbReg, points=np.linspace(-1, 1, 1000), pset=pset)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "toolbox.register(\"mate\", gp.cxOnePoint)\n",
    "toolbox.register(\"expr_mut\", gp.genFull, min_=0, max_=2)\n",
    "toolbox.register(\"mutate\", gp.mutUniform, expr=toolbox.expr_mut, pset=pset)\n",
    "toolbox.register(\"insert\" , gp.mutInsert, pset=pset)\n",
    "toolbox.decorate(\"mate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value=17))\n",
    "toolbox.decorate(\"mutate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value=17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel(individual):\n",
    "    k = individual[0]\n",
    "    if k == 'svcLinear':\n",
    "        clf = LinearSVC(C=individual[0])\n",
    "    elif k == 'rbf':\n",
    "        clf = SVC(kernel=k, C=individual[0],gamma=individual[1])\n",
    "    else:\n",
    "        #linear\n",
    "        clf = SVC(kernel=k, C=individual[0])\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getXy(individual):\n",
    "    scols = list(cols)\n",
    "    for i in range(len(individual[0:])):\n",
    "        if individual[0+i]<1: scols.remove(cols[i])\n",
    "    #print(\"Selected cols: \",scols)\n",
    "    tcols = np.append(['Survived'],scols)\n",
    "    df = training.loc[:,tcols].dropna()\n",
    "    X = df.loc[:,scols]\n",
    "    scaler = preprocessing.StandardScaler().fit(X)    \n",
    "    #scaler= preprocessing.MinMaxScaler().fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    y = np.ravel(df.loc[:,['Survived']])\n",
    "    return [X,y,scols,scaler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Generation 0 --\n",
      "  Min 0.4337245151489531\n",
      "  Max 61.451809436860046\n",
      "  Avg 1.79771218553244\n",
      "  Std 4.567363248560968\n",
      "-- Generation 1 --\n",
      "  Min 0.3868993273134971\n",
      "  Max 3276.1038036535792\n",
      "  Avg 6.854575755619995\n",
      "  Std 110.45698572235884\n",
      "-- Generation 2 --\n",
      "  Min 0.3868993273134971\n",
      "  Max 222.89402459215046\n",
      "  Avg 6.168052498712462\n",
      "  Std 20.66653490320089\n",
      "-- Generation 3 --\n",
      "  Min 0.5056866194019045\n",
      "  Max 479.88115661427827\n",
      "  Avg 13.33329482976682\n",
      "  Std 36.848220104015134\n",
      "-- Generation 4 --\n",
      "  Min 0.5056866194019045\n",
      "  Max 479.6068849356344\n",
      "  Avg 24.500896632722206\n",
      "  Std 47.492585138899635\n",
      "-- Generation 5 --\n",
      "  Min 0.3868993273134971\n",
      "  Max 371.2859344536495\n",
      "  Avg 43.644197848414436\n",
      "  Std 59.07946458146618\n",
      "-- Generation 6 --\n",
      "  Min 0.4337245151489531\n",
      "  Max 3276.1491490694825\n",
      "  Avg 75.93074583787343\n",
      "  Std 169.665862711103\n",
      "-- Generation 7 --\n",
      "  Min 0.7775982335295882\n",
      "  Max 3276.1491490694825\n",
      "  Avg 112.59990235772976\n",
      "  Std 195.51678852123004\n",
      "-- Generation 8 --\n",
      "  Min 0.7779404679928336\n",
      "  Max 407267756.5208176\n",
      "  Avg 461368.80252151337\n",
      "  Std 13697883.591875289\n",
      "-- Generation 9 --\n",
      "  Min 0.7779404679928336\n",
      "  Max 407267756.5208176\n",
      "  Avg 922652.4722583031\n",
      "  Std 19360745.455732442\n",
      "-- Generation 10 --\n",
      "  Min 0.552708615587239\n",
      "  Max 407267756.5208176\n",
      "  Avg 461613.7279243432\n",
      "  Std 13697876.165432682\n",
      "-- Generation 11 --\n",
      "  Min 0.7987020718455218\n",
      "  Max 23054876903.496574\n",
      "  Avg 27955122.615063164\n",
      "  Std 775838977.0562251\n",
      "-- Generation 12 --\n",
      "  Min 0.3868993273134971\n",
      "  Max 23054876903.496574\n",
      "  Avg 29338778.68127339\n",
      "  Std 776151002.3596365\n",
      "-- Generation 13 --\n",
      "  Min 0.7775982335295882\n",
      "  Max 23054876903.496574\n",
      "  Avg 57754863.78300753\n",
      "  Std 1096736510.295655\n",
      "-- Generation 14 --\n",
      "  Min 0.5753171145104033\n",
      "  Max 23054876903.496574\n",
      "  Avg 115970381.41452666\n",
      "  Std 1548893768.7211616\n",
      "-- Generation 15 --\n",
      "  Min 0.7109665599997124\n",
      "  Max 516439933424687.4\n",
      "  Avg 584944507481.2294\n",
      "  Std 17369741023914.684\n",
      "-- Generation 16 --\n",
      "  Min 0.7858531853577936\n",
      "  Max 516439933424687.4\n",
      "  Avg 584927161231.7882\n",
      "  Std 17369741590834.414\n",
      "-- Generation 17 --\n",
      "  Min 0.5056866194019045\n",
      "  Max 23054876903.659615\n",
      "  Avg 131833005.15483047\n",
      "  Std 1345466002.936967\n",
      "-- Generation 18 --\n",
      "  Min 0.7987020718455218\n",
      "  Max 23054876903.659615\n",
      "  Avg 263484468.84841716\n",
      "  Std 2043805863.9037683\n",
      "-- Generation 19 --\n",
      "  Min 0.7779404679928336\n",
      "  Max 23054876903.659615\n",
      "  Avg 335997889.0535082\n",
      "  Std 2312109327.1988482\n",
      "-- Generation 20 --\n",
      "  Min 0.7987020718455218\n",
      "  Max 23054876903.659615\n",
      "  Avg 456425950.17743856\n",
      "  Std 2768514560.0581903\n",
      "-- Generation 21 --\n",
      "  Min 0.7987020718455218\n",
      "  Max 23054876903.659615\n",
      "  Avg 623485533.1492294\n",
      "  Std 3287758670.738725\n",
      "-- Generation 22 --\n",
      "  Min 0.7987020718455218\n",
      "  Max 23054876903.659615\n",
      "  Avg 744221217.1035105\n",
      "  Std 3613674923.8398376\n",
      "-- Generation 23 --\n",
      "  Min 0.7779404679928336\n",
      "  Max 23054876903.659615\n",
      "  Avg 858091724.8095092\n",
      "  Std 3947006638.485096\n",
      "-- Generation 24 --\n",
      "  Min 0.7779404679928336\n",
      "  Max 23054876903.659615\n",
      "  Avg 1041782120.6799861\n",
      "  Std 4409528561.992165\n",
      "-- Generation 25 --\n",
      "  Min 0.7775982335295882\n",
      "  Max 23054876903.659615\n",
      "  Avg 1414697790.5380518\n",
      "  Std 5192135883.40846\n",
      "-- Generation 26 --\n",
      "  Min 0.7775982335295882\n",
      "  Max 23054876903.659615\n",
      "  Avg 1979653043.449352\n",
      "  Std 6211296536.959549\n",
      "-- Generation 27 --\n",
      "  Min 0.7775982335295882\n",
      "  Max 23054876903.659615\n",
      "  Avg 2838857652.458906\n",
      "  Std 7349979647.983568\n",
      "-- Generation 28 --\n",
      "  Min 0.552708615587239\n",
      "  Max 23054876903.659615\n",
      "  Avg 3574999991.9242744\n",
      "  Std 8152176155.4822235\n",
      "-- Generation 29 --\n",
      "  Min 0.7987020718455218\n",
      "  Max 23054876903.659615\n",
      "  Avg 4180657552.335855\n",
      "  Std 8682723192.600111\n",
      "-- Generation 30 --\n",
      "  Min 0.7987020718455218\n",
      "  Max 23054876903.659615\n",
      "  Avg 5425886976.353939\n",
      "  Std 9612005178.046417\n",
      "-- Generation 31 --\n",
      "  Min 0.7775982335295882\n",
      "  Max 23054876903.659615\n",
      "  Avg 6825529804.812419\n",
      "  Std 10381225054.026026\n",
      "-- Generation 32 --\n",
      "  Min 0.7867497709397611\n",
      "  Max 23054876903.659615\n",
      "  Avg 8382039180.687507\n",
      "  Std 11015045926.826126\n",
      "-- Generation 33 --\n",
      "  Min 0.5056866194019045\n",
      "  Max 23054876903.659615\n",
      "  Avg 8830740230.2202\n",
      "  Std 11141961129.350443\n",
      "-- Generation 34 --\n",
      "  Min 0.4337245151489531\n",
      "  Max 23054876903.659615\n",
      "  Avg 8372799218.610823\n",
      "  Std 11051568391.76828\n",
      "-- Generation 35 --\n",
      "  Min 0.7987020718455218\n",
      "  Max 23054876903.659615\n",
      "  Avg 9088937637.827827\n",
      "  Std 11245948429.94778\n",
      "-- Generation 36 --\n",
      "  Min 0.8625270240037809\n",
      "  Max 23054876903.659615\n",
      "  Avg 8791645324.973156\n",
      "  Std 11166777809.883245\n",
      "-- Generation 37 --\n",
      "  Min 0.7987020718455218\n",
      "  Max 23054876903.659615\n",
      "  Avg 8499627604.336155\n",
      "  Std 11078812487.9458\n",
      "-- Generation 38 --\n",
      "  Min 0.7987020718455218\n",
      "  Max 23056935518.698963\n",
      "  Avg 8585742182.623761\n",
      "  Std 11114975000.868433\n",
      "-- Generation 39 --\n",
      "  Min 0.7987020718455218\n",
      "  Max 516440435408660.56\n",
      "  Avg 592489939933.2362\n",
      "  Std 17369507187848.14\n",
      "-- End of (successful) evolution --\n",
      "Best individual is negative(tan(add(add(tan(sin(cos(add(sin(x), x)))), sin(x)), x))), (516440435408660.56,)\n"
     ]
    }
   ],
   "source": [
    "gen = range(40)\n",
    "avg_list = []\n",
    "max_list = []\n",
    "min_list = []\n",
    "\n",
    "pop = toolbox.population(n=883)\n",
    "\n",
    "# Evaluate the entire population\n",
    "fitnesses = list(map(toolbox.evaluate, pop))\n",
    "for ind, fit in zip(pop, fitnesses):\n",
    "    ind.fitness.values = fit\n",
    "\n",
    "# Begin the evolution\n",
    "for g in gen:\n",
    "    print(\"-- Generation %i --\" % g)\n",
    "\n",
    "    # Select the next generation individuals\n",
    "    offspring = toolbox.select(pop, len(pop))\n",
    "    # Clone the selected individuals\n",
    "    offspring = list(map(toolbox.clone, offspring))\n",
    "\n",
    "    # Apply crossover and mutation on the offspring\n",
    "    for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "        if random.random() < 0.5:\n",
    "            toolbox.mate(child1, child2)\n",
    "            del child1.fitness.values\n",
    "            del child2.fitness.values\n",
    "\n",
    "    for mutant in offspring:\n",
    "        if random.random() < 0.2:\n",
    "            toolbox.mutate(mutant)\n",
    "            del mutant.fitness.values\n",
    "\n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "    fitnesses = map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    # Replace population\n",
    "    pop[:] = offspring\n",
    "\n",
    "    # Gather all the fitnesses in one list and print the stats\n",
    "    fits = [ind.fitness.values[0] for ind in pop]\n",
    "\n",
    "    length = len(pop)\n",
    "    mean = sum(fits) / length\n",
    "    sum2 = sum(x*x for x in fits)\n",
    "    std = abs(sum2 / length - mean**2)**0.5\n",
    "    g_max = max(fits)\n",
    "    g_min = min(fits)\n",
    "        \n",
    "    avg_list.append(mean)\n",
    "    max_list.append(g_max)\n",
    "    min_list.append(g_min)\n",
    "\n",
    "    print(\"  Min %s\" % g_min)\n",
    "    print(\"  Max %s\" % g_max)\n",
    "    print(\"  Avg %s\" % mean)\n",
    "    print(\"  Std %s\" % std)\n",
    "\n",
    "print(\"-- End of (successful) evolution --\")\n",
    "\n",
    "best_ind = tools.selBest(pop, 1)[0]\n",
    "print(\"Best individual is %s, %s\" % (best_ind, best_ind.fitness.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-da9ed8e948a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_ind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mXy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetXy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_ind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mcolsSVM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-e06c99bdc6bb>\u001b[0m in \u001b[0;36mgetXy\u001b[1;34m(individual)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgetXy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindividual\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mscols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindividual\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindividual\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mscols\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m#print(\"Selected cols: \",scols)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "selCols = []\n",
    "#filtering only numeric attributes\n",
    "for col in test_data.columns:\n",
    "    if(test_data[col].dtype == 'int64' or test_data[col].dtype == 'float64' or test_data[col].dtype == 'uint8'):\n",
    "        selCols.append(col)  \n",
    "cols = selCols\n",
    "test_ind = best_ind.fitness.values[0]\n",
    "model = getModel(best_ind)\n",
    "\n",
    "Xy = getXy(test_ind)\n",
    "colsSVM = Xy[2]\n",
    "scaler = Xy[3]\n",
    "print(\"Selected Features: \",colsSVM)\n",
    "\n",
    "X_train = Xy[0]\n",
    "Y_train = Xy[1]\n",
    "\n",
    "model.fit( X_train , y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_truth = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_truth, y_pred).ravel()\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_truth, y_pred, labels=[0, 1]))\n",
    "print(\"\")\n",
    "print(\"True Negatives\", tn)\n",
    "print(\"False Positives\", fp)\n",
    "print(\"False Negatives\", fn)\n",
    "print(\"True Positives\", tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(predictions)\n",
    "pred_df = pd.DataFrame(predictions, index=test_data.index, columns=['Survived'])\n",
    "type(pred_df)\n",
    "pred_df.to_csv('predictions.csv', header=True, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
